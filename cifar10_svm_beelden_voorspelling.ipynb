{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4d0e6d90",
      "metadata": {
        "id": "4d0e6d90"
      },
      "source": [
        "# üìö Klassieke Machine‚ÄëLearning Demo: CIFAR‚Äë10 met SVM\n",
        "\n",
        "In dit project laten we zien hoe je **CIFAR‚Äë10** ‚Äì een beeld¬≠dataset ‚Äì toch met een **klassiek ML‚Äëmodel** (Support Vector Machine) kunt aanpakken, z√≥nder deep learning.\n",
        "\n",
        "> **Belangrijk verschil** ‚Üî Bij een CNN (Deep Learning model) leert het netwerk zelf visuele patronen. Met een klassiek ML‚Äëmodel moeten we de afbeeldingen **flattenen** tot tabellen en (optioneel) de dimensie verkleinen met PCA. Dat is minder krachtig, maar je kan alsnog de klassieke ML‚Äêprincipes toepassen."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb749bfa",
      "metadata": {
        "id": "eb749bfa"
      },
      "source": [
        "## üì¶ Stap¬†1¬†‚Äì Dataset importeren & verkennen\n",
        "We halen CIFAR‚Äë10 binnen via Keras. Daarna printen we de vorm en bekijken we enkele voorbeelden."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c01ec9bc",
      "metadata": {
        "id": "c01ec9bc"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "print('Train shape:', X_train.shape)\n",
        "print('Test shape:', X_test.shape)\n",
        "\n",
        "class_names = ['vliegtuig','auto','vogel','kat','hert','hond','kikker','paard','schip','vrachtwagen']\n",
        "\n",
        "# Voorbeeldbeelden tonen\n",
        "plt.figure(figsize=(10,4))\n",
        "for i in range(10):\n",
        "    plt.subplot(2,5,i+1)\n",
        "    plt.imshow(X_train[i])\n",
        "    plt.title(class_names[int(y_train[i])])\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîç Wat gebeurt hier?\n",
        "We laden CIFAR-10 in via Keras. Het bevat 60.000 kleurafbeeldingen van 32√ó32 pixels, verdeeld over 10 klassen (zoals hond, kat, vliegtuig, auto).\n",
        "\n",
        "Keras splitst het alvast in een trainingsset (50.000) en een testset (10.000).\n",
        "\n",
        "Elke afbeelding heeft 3 kleurkanalen (RGB), dus een vorm van (32, 32, 3).\n",
        "\n",
        "## üìà Waarom verkennen?\n",
        "We checken de vorm en kwaliteit van de data.\n",
        "\n",
        "Het is belangrijk om te zien wat je model gaat leren. Beeldherkenning is een visueel probleem.\n",
        "\n"
      ],
      "metadata": {
        "id": "8AhUEWcs3edd"
      },
      "id": "8AhUEWcs3edd"
    },
    {
      "cell_type": "markdown",
      "id": "88dc6aa7",
      "metadata": {
        "id": "88dc6aa7"
      },
      "source": [
        "## üßπ Stap¬†2¬†‚Äì Data omzetten voor klassiek ML‚Äëgebruik\n",
        "1. **Flattenen**: 32√ó32√ó3¬†‚Üí¬†1√ó3072 vector.\n",
        "2. **Schalen**: delen door¬†255 zodat alle waarden tussen¬†0‚Äì1 liggen.\n",
        "3. (Optioneel) **Dimensiereductie met PCA** om training te versnellen.\n",
        "\n",
        "> Bij 50¬†000 trainingsbeelden √ó¬†3072 features kan SVM traag worden. Voor demo‚Äëdoeleinden pakken we een **subset van 15‚ÄØ000 samples**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "995099ed",
      "metadata": {
        "id": "995099ed"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Flatten en schalen\n",
        "X_train_flat = X_train.reshape(-1, 32*32*3) / 255.0\n",
        "X_test_flat  = X_test.reshape(-1, 32*32*3) / 255.0\n",
        "\n",
        "# Subset voor snelheid\n",
        "subset = 15000\n",
        "X_sub, _, y_sub, _ = train_test_split(X_train_flat, y_train, train_size=subset, stratify=y_train, random_state=42)\n",
        "\n",
        "print('Subset shape:', X_sub.shape)\n",
        "\n",
        "# PCA naar 100 componenten (versnelt SVM zonder al te veel info te verliezen)\n",
        "pca = PCA(n_components=100, random_state=42)\n",
        "X_sub_pca = pca.fit_transform(X_sub)\n",
        "X_test_pca = pca.transform(X_test_flat)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8cb7466c",
      "metadata": {
        "id": "8cb7466c"
      },
      "source": [
        "## üß† Stap¬†3¬†‚Äì Support Vector Machine trainen\n",
        "We gebruiken een **SVC** met RBF‚Äëkernel. Dit is een krachtig model voor niet‚Äëlineaire patronen. Door PCA is het aantal features nu 100 i.p.v. 3072, waardoor training sneller gaat.\n",
        "\n",
        "## üîÅ Wat gebeurt er bij max_iter=10?\n",
        "max_iter=10 betekent: 10 volledige ‚Äúepochs‚Äù over de trainingsdata.\n",
        "\n",
        "Een epoch = √©√©n keer alle trainingsvoorbeelden door het model halen.\n",
        "\n",
        "Na elke epoch wordt het model bijgesteld op basis van fouten.\n",
        "\n",
        "## üí¨ Waarom herhaalt het zich?\n",
        "De herhaling (de epochs) zijn nodig omdat:\n",
        "\n",
        "Het model bij elke ronde bijleert en bijstelt.\n",
        "\n",
        "Na √©√©n ronde (epoch) is het meestal nog niet goed genoeg.\n",
        "\n",
        "Elke epoch zorgt voor een kleine verbetering, tot het convergentie bereikt of max_iter is bereikt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc149365",
      "metadata": {
        "id": "dc149365"
      },
      "outputs": [],
      "source": [
        "# from sklearn.svm import SVC\n",
        "\n",
        "# svm = SVC(kernel='rbf', gamma='scale', C=10, random_state=42)\n",
        "# svm.fit(X_sub_pca, y_sub.ravel())  # ravel ‚Üí 1D labels\n",
        "# print('Model getraind!')\n",
        "\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "svm = SGDClassifier(loss='hinge', max_iter=10, verbose=1)\n",
        "svm.fit(X_sub_pca, y_sub.ravel())\n",
        "print('Model getraind!')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîç Wat is een SVM?\n",
        "Een SVM probeert een grensvlak te vinden tussen verschillende klassen in de data.\n",
        "\n",
        "Met een RBF-kernel kunnen we ook niet-lineaire grenzen trekken (bijvoorbeeld als honden en katten niet perfect gescheiden zijn in een rechte lijn).\n",
        "\n",
        "C regelt de mate waarin fouten worden bestraft (groter = strenger)\n",
        "\n",
        "## üß† Waarom is dit klassiek ML?\n",
        "We voeren het model platte rijen van getallen in, geen ruwe beelden\n",
        "\n",
        "Geen deep learning-lagen, geen automatische feature learning ‚Äì alles moet vooraf worden klaargemaakt\n",
        "\n"
      ],
      "metadata": {
        "id": "zwmrLSTP3rBA"
      },
      "id": "zwmrLSTP3rBA"
    },
    {
      "cell_type": "markdown",
      "id": "12f52c6e",
      "metadata": {
        "id": "12f52c6e"
      },
      "source": [
        "## ‚úÖ Stap¬†4¬†‚Äì Evaluatie op de testset\n",
        "\n",
        "We testen het model op de volledige testset.\n",
        "\n",
        "We kijken naar **accuracy**, een classificatierapport en een verwarringsmatrix om te zien welke klassen moeilijk zijn.\n",
        "\n",
        "classification_report() toont:\n",
        "\n",
        "**Precision**: Hoeveel van de voorspelde katten w√°ren echt katten?\n",
        "\n",
        "**Recall**: Hoeveel van alle echte katten heeft het model gevonden?\n",
        "\n",
        "**F1-score**: Gemiddelde tussen precision en recall\n",
        "\n",
        "**Accuracy**: Hoeveel is er totaal goed voorspeld?\n",
        "\n",
        "## üìâ Je mag verwachten:\n",
        "Accuracy is meestal rond 35‚Äì45%. Dat lijkt laag, maar met 10 klassen is random gokken slechts 10%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d45d119",
      "metadata": {
        "id": "3d45d119"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "y_pred = svm.predict(X_test_pca)\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(f'Test‚Äëaccuracy: {acc:.2f}')\n",
        "\n",
        "print(classification_report(y_test, y_pred, target_names=class_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2ff3f73",
      "metadata": {
        "id": "f2ff3f73"
      },
      "source": [
        "### üîé Verwarringsmatrix visualiseren"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1263304",
      "metadata": {
        "id": "d1263304"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.imshow(cm, interpolation='nearest')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.colorbar()\n",
        "plt.xticks(np.arange(10), class_names, rotation=45)\n",
        "plt.yticks(np.arange(10), class_names)\n",
        "plt.ylabel('Echte label')\n",
        "plt.xlabel('Voorspelde label')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9846b4a7",
      "metadata": {
        "id": "9846b4a7"
      },
      "source": [
        "## üñºÔ∏è Bonus¬†‚Äì Enkele voorbeelden inspecteren\n",
        "Bekijk tien willekeurige testbeelden met de voorspelling (groen = correct, rood = fout)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "334cfc73",
      "metadata": {
        "id": "334cfc73"
      },
      "outputs": [],
      "source": [
        "indices = np.random.choice(len(X_test), 10, replace=False)\n",
        "plt.figure(figsize=(10,4))\n",
        "for i, idx in enumerate(indices):\n",
        "    img = X_test[idx]\n",
        "    true_label = int(y_test[idx])\n",
        "    pred_label = int(y_pred[idx])\n",
        "    plt.subplot(2,5,i+1)\n",
        "    plt.imshow(img)\n",
        "    kleur = 'green' if true_label==pred_label else 'red'\n",
        "    plt.title(class_names[pred_label], color=kleur)\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1a7feef",
      "metadata": {
        "id": "c1a7feef"
      },
      "source": [
        "## üìä Reflectie\n",
        "- **Accuracy** zal lager zijn dan bij een CNN (vaak ~35‚Äë45‚ÄØ%).\n",
        "- Toch zie je dat **klassieke ML** ook op beelddata toepasbaar is.\n",
        "- Voor productie‚Äëtoepassingen met afbeeldingen is **deep learning** meestal de betere keuze, maar dit experiment toont hoe data‚Äërepresentatie een groot verschil maakt.\n",
        "\n",
        "**Vervolgidee√´n:**\n",
        "1. Speel met aantal PCA‚Äëcomponenten en `C`, `gamma` van de SVM.\n",
        "2. Probeer andere ML‚Äëmodellen zoals RandomForest of K‚ÄëNN."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}